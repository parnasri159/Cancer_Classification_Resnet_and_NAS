{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7273440,"sourceType":"datasetVersion","datasetId":4216644},{"sourceId":9537604,"sourceType":"datasetVersion","datasetId":2058865}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lymphoma Diagnosis in Histopathology Images\n\n## Introduction\n\nThis Jupyter notebook explores a Convolutional Neural Network (CNN) based approach for diagnosing lymphoma in histopathology images. Lymphoma, a type of cancer that originates in the lymphatic system, can be challenging to diagnose accurately. Histopathology images, which provide microscopic views of tissue samples, are crucial for the identification of cancerous cells.\n\nIn this project, we leverage the power of deep learning techniques, specifically employing Convolutional Neural Networks (CNNs), to automate and enhance the process of lymphoma diagnosis. Additionally, we incorporate Neural Architecture Search (NAS) as an optimization technique. NAS allows us to automatically discover optimal neural network architectures, potentially improving both accuracy and efficiency.\n\n## Objectives\n\n- Develop a CNN-based model for accurate lymphoma diagnosis in histopathology images.\n- Utilize Neural Architecture Search (NAS) to automatically discover an optimized neural network architecture.\n- Evaluate the model's performance on a dataset of histopathology images, considering factors such as accuracy, precision, recall, and F1-score.\n- Provide insights into the potential benefits of employing NAS in optimizing deep learning models for medical image analysis.\n\n## Dataset\n\n    For the dataset, we are using “Multi Cancer Dataset” based on a publication of the IEEE Engineering in Medicine and\n    Biology Society: “Automatic Classification of Lymphoma Images With Transform-Based Global Features” by Orlov,\n    Nikita and Chen, Wayne and Eckley, David and Macura, Tomasz and Shamir, Lior and Jaffe, Elaine and Goldberg, Ilya\n    (2010)\nThis dataset contains:\n* 20 000 images of Acute Lymphoblastic Leukemia\n* 15 000 images of Brain Cancer\n* 10 000 images of Breast Cancer\n* 25 000 images of Cervical Cancer\n* 10 000 images of Kidney Cancer\n* 25 000 images of Lung and Colon Cancer\n* 10 000 images of Oral Cancer\n* 15 000 images of Lymphoma\n\n\n#### We are working on those 15 000 images of Lymphoma and they are divided into 3 subclasses as follows:\n* 5 000 images of “Chronic Lymphocytic Leukemia”\n* 5 000 images of “Follicular Lymphoma”\n* 5 000 images of “Mantle Cell Lymphoma”\n\n##### Here is an example on each subclass:\n![](https://i.imgur.com/nBKrFie.jpeg)\n![](https://i.imgur.com/0P6CkHF.jpeg)\n![](https://i.imgur.com/uPQCYpC.jpeg)\n\n######   (a) Chronic Lymphocytic Leukemia  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     (b) Follicular Lymphoma  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  (c) Mantle Cell Lymphoma\n## Methodology\n\n1. **Data Preprocessing**: Prepare and preprocess the histopathology images to make them suitable for training the CNN.\n2. **Model Architecture**: Design and implement a CNN architecture for lymphoma diagnosis.\n3. **Neural Architecture Search (NAS)**: Apply NAS to automatically search for an optimized neural network architecture.\n4. **Model Training**: Train the CNN model on the preprocessed dataset, utilizing the NAS-discovered architecture.\n5. **Evaluation**: Evaluate the model's performance using various metrics to assess its accuracy and effectiveness in lymphoma diagnosis.\n\nBy the end of this notebook, we aim to present an efficient and accurate deep learning model for automating lymphoma diagnosis, showcasing the potential improvements achieved through the integration of Neural Architecture Search.\n","metadata":{}},{"cell_type":"markdown","source":"### 1. Data","metadata":{}},{"cell_type":"markdown","source":"#### 1.1 Path Setup","metadata":{}},{"cell_type":"code","source":"data_path_cll = \"/kaggle/input/multi-cancer/Multi Cancer/Lymphoma/lymph_cll\"\ndata_path_fl = \"/kaggle/input/multi-cancer/Multi Cancer/Lymphoma/lymph_fl\"\ndata_path_mcl = \"/kaggle/input/multi-cancer/Multi Cancer/Lymphoma/lymph_mcl\"","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:47:49.818834Z","iopub.execute_input":"2023-12-24T22:47:49.819639Z","iopub.status.idle":"2023-12-24T22:47:49.824038Z","shell.execute_reply.started":"2023-12-24T22:47:49.819601Z","shell.execute_reply":"2023-12-24T22:47:49.823073Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.2 Loading Data","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\ndef load_images_with_labels(folder_path: str, label: int, img_size: tuple = (128, 128)) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Load images from a specified folder, resize them, and assign labels.\n\n    Parameters:\n    - folder_path (str): The path to the folder containing images.\n    - label (int): The label to assign to the loaded images.\n    - img_size (tuple): The target size for the images after resizing (default: (128, 128)).\n\n    Returns:\n    - Tuple of NumPy arrays: (images, labels)\n      - images (np.ndarray): Array of resized and normalized images.\n      - labels (np.ndarray): Array of corresponding labels.\n    \"\"\"\n    images = []\n    labels = []\n\n    for filename in os.listdir(folder_path):\n        img_path = os.path.join(folder_path, filename)\n        print(f\"Loading image: {img_path}\")\n\n        img = cv2.imread(img_path)\n\n        if img is None:\n            print(f\"Error loading image: {img_path}\")\n            continue\n\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, img_size)\n        images.append(img)\n        labels.append(label)\n\n    return np.array(images) / 255.0, np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:47:49.825643Z","iopub.execute_input":"2023-12-24T22:47:49.825923Z","iopub.status.idle":"2023-12-24T22:47:50.005083Z","shell.execute_reply.started":"2023-12-24T22:47:49.8259Z","shell.execute_reply":"2023-12-24T22:47:50.004345Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_dict = { 0 : 'Chronic Lymphocytic Leukemia',1 : 'Follicular Lymphoma', 2 : 'Mantle Cell Lymphoma'}","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:47:50.006288Z","iopub.execute_input":"2023-12-24T22:47:50.006884Z","iopub.status.idle":"2023-12-24T22:47:50.011411Z","shell.execute_reply.started":"2023-12-24T22:47:50.006849Z","shell.execute_reply":"2023-12-24T22:47:50.010533Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lymph_cll = load_images_with_labels(folder_path = data_path_cll, label = 0)\nlymph_fl  = load_images_with_labels(folder_path = data_path_fl , label = 1)\nlymph_mcl = load_images_with_labels(folder_path = data_path_mcl, label = 2)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:47:50.013631Z","iopub.execute_input":"2023-12-24T22:47:50.013951Z","iopub.status.idle":"2023-12-24T22:51:04.64705Z","shell.execute_reply.started":"2023-12-24T22:47:50.013921Z","shell.execute_reply":"2023-12-24T22:51:04.64614Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lymph_cll_images, lymph_cll_labels = lymph_cll[0], lymph_cll[1]\nlymph_fl_images,  lymph_fl_labels  = lymph_fl[0],  lymph_fl[1]\nlymph_mcl_images, lymph_mcl_labels = lymph_mcl[0], lymph_mcl[1]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:04.648328Z","iopub.execute_input":"2023-12-24T22:51:04.648617Z","iopub.status.idle":"2023-12-24T22:51:04.653504Z","shell.execute_reply.started":"2023-12-24T22:51:04.648593Z","shell.execute_reply":"2023-12-24T22:51:04.65242Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.3 Split data into Train, test and validate","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:04.654817Z","iopub.execute_input":"2023-12-24T22:51:04.655481Z","iopub.status.idle":"2023-12-24T22:51:05.57995Z","shell.execute_reply.started":"2023-12-24T22:51:04.655448Z","shell.execute_reply":"2023-12-24T22:51:05.579202Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 1.3.1 Train and test Split","metadata":{}},{"cell_type":"code","source":"#Chronic Lymphocytic Leukemia\nX_train_validate_cll, X_test_cll, y_train_validate_cll, y_test_cll = train_test_split(lymph_cll_images, lymph_cll_labels, test_size=0.2, random_state=42)\n#Follicular Lymphoma\nX_train_validate_fl,  X_test_fl,  y_train_validate_fl,  y_test_fl  = train_test_split(lymph_fl_images,  lymph_fl_labels,  test_size=0.2, random_state=42)\n#Mantle Cell Lymphoma\nX_train_validate_mcl, X_test_mcl, y_train_validate_mcl, y_test_mcl = train_test_split(lymph_mcl_images, lymph_mcl_labels, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:05.58103Z","iopub.execute_input":"2023-12-24T22:51:05.58133Z","iopub.status.idle":"2023-12-24T22:51:07.25896Z","shell.execute_reply.started":"2023-12-24T22:51:05.581305Z","shell.execute_reply":"2023-12-24T22:51:07.258158Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 1.3.2 Train and validate split","metadata":{}},{"cell_type":"code","source":"#Chronic Lymphocytic Leukemia\nX_train_cll, X_val_cll, y_train_cll, y_val_cll = train_test_split(X_train_validate_cll, y_train_validate_cll, test_size=0.2, random_state=42)\n#Follicular Lymphoma\nX_train_fl,  X_val_fl,  y_train_fl,  y_val_fl  = train_test_split(X_train_validate_fl,  y_train_validate_fl,  test_size=0.2, random_state=42)\n#Mantle Cell Lymphoma\nX_train_mcl, X_val_mcl, y_train_mcl, y_val_mcl = train_test_split(X_train_validate_mcl, y_train_validate_mcl, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:07.260156Z","iopub.execute_input":"2023-12-24T22:51:07.260513Z","iopub.status.idle":"2023-12-24T22:51:08.57689Z","shell.execute_reply.started":"2023-12-24T22:51:07.260481Z","shell.execute_reply":"2023-12-24T22:51:08.575858Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 1.3.3 Concatenate Data","metadata":{}},{"cell_type":"code","source":"X_train = np.concatenate((X_train_cll, X_train_fl,X_train_mcl), axis=0)\nX_test  = np.concatenate((X_test_cll,  X_test_fl ,X_test_mcl ), axis=0)\nX_val   = np.concatenate((X_val_cll,   X_val_fl  ,X_val_mcl  ), axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:08.58005Z","iopub.execute_input":"2023-12-24T22:51:08.580379Z","iopub.status.idle":"2023-12-24T22:51:10.567833Z","shell.execute_reply.started":"2023-12-24T22:51:08.58034Z","shell.execute_reply":"2023-12-24T22:51:10.567058Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = np.concatenate((y_train_cll, y_train_fl,y_train_mcl), axis=0)\ny_test  = np.concatenate((y_test_cll,  y_test_fl ,y_test_mcl ), axis=0)\ny_val   = np.concatenate((y_val_cll,   y_val_fl  ,y_val_mcl  ), axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:10.568894Z","iopub.execute_input":"2023-12-24T22:51:10.569182Z","iopub.status.idle":"2023-12-24T22:51:10.574378Z","shell.execute_reply.started":"2023-12-24T22:51:10.569157Z","shell.execute_reply":"2023-12-24T22:51:10.573502Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 1.3.4 Shapes Check ","metadata":{}},{"cell_type":"code","source":"print(f'X_train : {X_train.shape} ,  y_train :  {y_train.shape}')\nprint(f'X_val   : {X_val.shape} ,  y_val   :  {y_val.shape}  ')\nprint(f'X_test  : {X_test.shape} ,  y_test  :  {y_test.shape} ')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:10.575572Z","iopub.execute_input":"2023-12-24T22:51:10.576133Z","iopub.status.idle":"2023-12-24T22:51:10.58459Z","shell.execute_reply.started":"2023-12-24T22:51:10.576108Z","shell.execute_reply":"2023-12-24T22:51:10.583717Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"    9600 Images train, 2400 images validate and 3000 images test","metadata":{}},{"cell_type":"markdown","source":"##### 1.3.5 Shuffle","metadata":{}},{"cell_type":"code","source":"# Generate an array of indices and shuffle them\nindices_train = np.arange(X_train.shape[0])\nindices_val   = np.arange(X_val.shape[0])\nindices_test  = np.arange(X_test.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:10.585664Z","iopub.execute_input":"2023-12-24T22:51:10.586368Z","iopub.status.idle":"2023-12-24T22:51:10.595768Z","shell.execute_reply.started":"2023-12-24T22:51:10.586343Z","shell.execute_reply":"2023-12-24T22:51:10.595067Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.shuffle(indices_train)\nnp.random.shuffle(indices_val)\nnp.random.shuffle(indices_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:10.596721Z","iopub.execute_input":"2023-12-24T22:51:10.596954Z","iopub.status.idle":"2023-12-24T22:51:10.608586Z","shell.execute_reply.started":"2023-12-24T22:51:10.596933Z","shell.execute_reply":"2023-12-24T22:51:10.607821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use the shuffled indices to shuffle both X_train and y_train\nX_train_shuffled = X_train[indices_train]\ny_train_shuffled = y_train[indices_train]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:10.609754Z","iopub.execute_input":"2023-12-24T22:51:10.610087Z","iopub.status.idle":"2023-12-24T22:51:12.727196Z","shell.execute_reply.started":"2023-12-24T22:51:10.610057Z","shell.execute_reply":"2023-12-24T22:51:12.726244Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use the shuffled indices to shuffle both X_val and y_val\nX_val_shuffled = X_val[indices_val]\ny_val_shuffled = y_val[indices_val]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:12.728362Z","iopub.execute_input":"2023-12-24T22:51:12.728651Z","iopub.status.idle":"2023-12-24T22:51:13.537413Z","shell.execute_reply.started":"2023-12-24T22:51:12.728627Z","shell.execute_reply":"2023-12-24T22:51:13.536626Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use the shuffled indices to shuffle both X_test and y_test\nX_test_shuffled = X_test[indices_test]\ny_test_shuffled = y_test[indices_test]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:13.538572Z","iopub.execute_input":"2023-12-24T22:51:13.538841Z","iopub.status.idle":"2023-12-24T22:51:14.492533Z","shell.execute_reply.started":"2023-12-24T22:51:13.538818Z","shell.execute_reply":"2023-12-24T22:51:14.491523Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Free Some memory !\ndel X_train, X_val, X_test, y_train, y_test, y_val, X_train_cll, X_val_cll, y_train_cll, y_val_cll, X_train_fl,  X_val_fl,  y_train_fl,  y_val_fl, X_train_mcl, X_val_mcl, y_train_mcl, y_val_mcl, X_train_validate_mcl, X_test_mcl, y_train_validate_mcl, y_test_mcl, X_train_validate_fl,  X_test_fl,  y_train_validate_fl,  y_test_fl,X_train_validate_cll, X_test_cll, y_train_validate_cll, y_test_cll \ndel lymph_cll_images, lymph_cll_labels, lymph_fl_images,  lymph_fl_labels, lymph_mcl_images, lymph_mcl_labels, lymph_cll, lymph_fl, lymph_mcl","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:14.493839Z","iopub.execute_input":"2023-12-24T22:51:14.494293Z","iopub.status.idle":"2023-12-24T22:51:14.546427Z","shell.execute_reply.started":"2023-12-24T22:51:14.49426Z","shell.execute_reply":"2023-12-24T22:51:14.545442Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.4 EDA (Exploratory Data Analysis)","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:14.547645Z","iopub.execute_input":"2023-12-24T22:51:14.547979Z","iopub.status.idle":"2023-12-24T22:51:15.407945Z","shell.execute_reply.started":"2023-12-24T22:51:14.547954Z","shell.execute_reply":"2023-12-24T22:51:15.406806Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.4.1 Visualize Class Distribution","metadata":{}},{"cell_type":"code","source":"y_mapped = [labels_dict[label] for label in y_train_shuffled]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:15.409247Z","iopub.execute_input":"2023-12-24T22:51:15.409698Z","iopub.status.idle":"2023-12-24T22:51:15.419889Z","shell.execute_reply.started":"2023-12-24T22:51:15.409665Z","shell.execute_reply":"2023-12-24T22:51:15.41867Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x=y_mapped)\nplt.title('Class Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:15.421249Z","iopub.execute_input":"2023-12-24T22:51:15.421568Z","iopub.status.idle":"2023-12-24T22:51:15.751773Z","shell.execute_reply.started":"2023-12-24T22:51:15.421538Z","shell.execute_reply":"2023-12-24T22:51:15.750949Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.4.2 Display Sample Images","metadata":{}},{"cell_type":"code","source":"def visualize_images(images, labels, class_names=None, num_samples=4):\n    num_rows = 1\n    num_cols = num_samples\n    plt.figure(figsize=(16, 16))\n\n    for i in range(num_samples):\n        \n        plt.subplot(num_rows, num_cols, i + 1)\n        plt.imshow(images[i])\n        if class_names:\n            plt.title(class_names[labels_dict[labels[i]]])\n        else:\n            plt.title(f\"Label: {labels_dict[labels[i]]}\")\n        plt.axis('off')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:15.752729Z","iopub.execute_input":"2023-12-24T22:51:15.752985Z","iopub.status.idle":"2023-12-24T22:51:15.759153Z","shell.execute_reply.started":"2023-12-24T22:51:15.752961Z","shell.execute_reply":"2023-12-24T22:51:15.758294Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display 5 random samples\nvisualize_images(X_train_shuffled, y_train_shuffled)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:15.760348Z","iopub.execute_input":"2023-12-24T22:51:15.760626Z","iopub.status.idle":"2023-12-24T22:51:16.290597Z","shell.execute_reply.started":"2023-12-24T22:51:15.760593Z","shell.execute_reply":"2023-12-24T22:51:16.289673Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.4.3 Explore Color Channels","metadata":{}},{"cell_type":"code","source":"# Explore color channels\ndef plot_color_channels(img):\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 4, 1)\n    plt.imshow(img)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    for i, channel in enumerate(['Red', 'Green', 'Blue']):\n        plt.subplot(1, 4, i + 2)\n        plt.imshow(img[:, :, i], cmap='gray')\n        plt.title(f'{channel} Channel')\n        plt.axis('off')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:16.291769Z","iopub.execute_input":"2023-12-24T22:51:16.292067Z","iopub.status.idle":"2023-12-24T22:51:16.298516Z","shell.execute_reply.started":"2023-12-24T22:51:16.292041Z","shell.execute_reply":"2023-12-24T22:51:16.297655Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_index = np.random.randint(0, len(X_train_shuffled))\nrandom_image = X_train_shuffled[random_index]\nplot_color_channels(random_image)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:16.303952Z","iopub.execute_input":"2023-12-24T22:51:16.304261Z","iopub.status.idle":"2023-12-24T22:51:16.744605Z","shell.execute_reply.started":"2023-12-24T22:51:16.304225Z","shell.execute_reply":"2023-12-24T22:51:16.743464Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.4.4 Pixel Intensity Distribution","metadata":{}},{"cell_type":"code","source":"# Explore pixel intensity distribution\ndef plot_pixel_intensity_distribution(img):\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.hist(img.ravel(), bins=256, color='gray', histtype='step')\n    plt.title('Pixel Intensity Distribution')\n    plt.xlabel('Pixel Intensity')\n    plt.ylabel('Frequency')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:16.745769Z","iopub.execute_input":"2023-12-24T22:51:16.7461Z","iopub.status.idle":"2023-12-24T22:51:16.752303Z","shell.execute_reply.started":"2023-12-24T22:51:16.746072Z","shell.execute_reply":"2023-12-24T22:51:16.751436Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_pixel_intensity_distribution(random_image)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:16.753517Z","iopub.execute_input":"2023-12-24T22:51:16.753839Z","iopub.status.idle":"2023-12-24T22:51:17.087842Z","shell.execute_reply.started":"2023-12-24T22:51:16.753809Z","shell.execute_reply":"2023-12-24T22:51:17.086943Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.4.5 Average Pixel Intensity per Class","metadata":{}},{"cell_type":"code","source":"# Calculate and visualize average pixel intensity per class\ndef average_pixel_intensity_per_class(X, y):\n    unique_classes = np.unique(y)\n    avg_intensity_per_class = []\n\n    for label in unique_classes:\n        class_indices = np.where(y == label)[0]\n        class_images = X[class_indices]\n        avg_intensity = np.mean(class_images)\n        avg_intensity_per_class.append(avg_intensity)\n\n    plt.bar(unique_classes, avg_intensity_per_class)\n    plt.title('Average Pixel Intensity per Class')\n    plt.xlabel('Class')\n    plt.ylabel('Average Pixel Intensity')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:17.089116Z","iopub.execute_input":"2023-12-24T22:51:17.089493Z","iopub.status.idle":"2023-12-24T22:51:17.096565Z","shell.execute_reply.started":"2023-12-24T22:51:17.089462Z","shell.execute_reply":"2023-12-24T22:51:17.095705Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize average pixel intensity per class\naverage_pixel_intensity_per_class(X_train_shuffled, y_train_shuffled)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:17.097757Z","iopub.execute_input":"2023-12-24T22:51:17.098086Z","iopub.status.idle":"2023-12-24T22:51:18.680665Z","shell.execute_reply.started":"2023-12-24T22:51:17.098056Z","shell.execute_reply":"2023-12-24T22:51:18.679811Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.4.6 Correlation Between Channels","metadata":{}},{"cell_type":"code","source":"# Explore correlation between color channels\ndef plot_channel_correlation(img):\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 4, 1)\n    plt.imshow(img)\n    plt.title('Original Image')\n    plt.axis('off')\n    \n    plt.subplot(1, 4, 2)\n    plt.scatter(img[:, :, 0].ravel(), img[:, :, (1) % 3].ravel(), s=2, alpha=0.5)\n    plt.title(f'Correlation: Red vs Green')\n    plt.xlabel(f'Red Channel')\n    plt.ylabel(f'Green Channel')\n    \n    plt.subplot(1, 4, 3)\n    plt.scatter(img[:, :, 1].ravel(), img[:, :, (2) % 3].ravel(), s=2, alpha=0.5)\n    plt.title(f'Correlation: Green vs Blue')\n    plt.xlabel(f'Green Channel')\n    plt.ylabel(f'Blue Channel')\n    \n    plt.subplot(1, 4, 4)\n    plt.scatter(img[:, :, 2].ravel(), img[:, :, (3) % 3].ravel(), s=2, alpha=0.5)\n    plt.title(f'Correlation: Blue vs Green')\n    plt.xlabel(f'Blue Channel')\n    plt.ylabel(f'Green Channel')\n\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:18.681827Z","iopub.execute_input":"2023-12-24T22:51:18.68212Z","iopub.status.idle":"2023-12-24T22:51:18.691434Z","shell.execute_reply.started":"2023-12-24T22:51:18.682095Z","shell.execute_reply":"2023-12-24T22:51:18.69037Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_channel_correlation(random_image)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:18.692649Z","iopub.execute_input":"2023-12-24T22:51:18.69297Z","iopub.status.idle":"2023-12-24T22:51:19.296158Z","shell.execute_reply.started":"2023-12-24T22:51:18.692938Z","shell.execute_reply":"2023-12-24T22:51:19.295235Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Model","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Use Naive ResNet","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:19.297231Z","iopub.execute_input":"2023-12-24T22:51:19.297488Z","iopub.status.idle":"2023-12-24T22:51:30.308033Z","shell.execute_reply.started":"2023-12-24T22:51:19.297465Z","shell.execute_reply":"2023-12-24T22:51:30.307236Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2.1.1 Load Pre-Trained ResNet-50 Version","metadata":{}},{"cell_type":"code","source":"# Load pre-trained ResNet50 model (excluding top classification layer)\nbase_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:30.309168Z","iopub.execute_input":"2023-12-24T22:51:30.309827Z","iopub.status.idle":"2023-12-24T22:51:35.71616Z","shell.execute_reply.started":"2023-12-24T22:51:30.309784Z","shell.execute_reply":"2023-12-24T22:51:35.715356Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Freeze the layers of the pre-trained ResNet model\nfor layer in base_resnet.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:35.717442Z","iopub.execute_input":"2023-12-24T22:51:35.718081Z","iopub.status.idle":"2023-12-24T22:51:35.729283Z","shell.execute_reply.started":"2023-12-24T22:51:35.718045Z","shell.execute_reply":"2023-12-24T22:51:35.728339Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2.1.2 Modeling on top of PreTrained Base ResNet-50","metadata":{}},{"cell_type":"code","source":"# Create a new model on top of the pre-trained ResNet model\nResNet50 = models.Sequential()\nResNet50.add(base_resnet)\nResNet50.add(layers.GlobalAveragePooling2D())\nResNet50.add(layers.Dense(256, activation='relu'))\nResNet50.add(layers.Dropout(0.5))\nResNet50.add(layers.Dense(3, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:35.730437Z","iopub.execute_input":"2023-12-24T22:51:35.730698Z","iopub.status.idle":"2023-12-24T22:51:36.285818Z","shell.execute_reply.started":"2023-12-24T22:51:35.730674Z","shell.execute_reply":"2023-12-24T22:51:36.285013Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2.1.3 One Hot Encoding","metadata":{}},{"cell_type":"code","source":"y_train_one_hot = to_categorical(y_train_shuffled, 3)\ny_val_one_hot   = to_categorical(y_val_shuffled, 3)\ny_test_one_hot  = to_categorical(y_test_shuffled, 3)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:36.286779Z","iopub.execute_input":"2023-12-24T22:51:36.287043Z","iopub.status.idle":"2023-12-24T22:51:36.292291Z","shell.execute_reply.started":"2023-12-24T22:51:36.28702Z","shell.execute_reply":"2023-12-24T22:51:36.291435Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ResNet50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:36.293809Z","iopub.execute_input":"2023-12-24T22:51:36.294144Z","iopub.status.idle":"2023-12-24T22:51:36.316569Z","shell.execute_reply.started":"2023-12-24T22:51:36.294113Z","shell.execute_reply":"2023-12-24T22:51:36.315904Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2.1.4 Train","metadata":{}},{"cell_type":"code","source":"res_net_history = ResNet50.fit(X_train_shuffled, y_train_one_hot, batch_size=32, epochs=10, validation_data=(X_val_shuffled, y_val_one_hot))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:51:36.317582Z","iopub.execute_input":"2023-12-24T22:51:36.317844Z","iopub.status.idle":"2023-12-24T22:53:19.40547Z","shell.execute_reply.started":"2023-12-24T22:51:36.317821Z","shell.execute_reply":"2023-12-24T22:53:19.404502Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2.1.5 Evaluation","metadata":{}},{"cell_type":"markdown","source":"##### 2.1.5.1 Plot Learning Curve","metadata":{}},{"cell_type":"code","source":"def plot_learning_curves(history):\n    plt.figure(figsize=(12, 6))\n\n    # Plot training & validation accuracy values\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend(['Train', 'Validate'], loc='upper left')\n\n    # Plot training & validation loss values\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(['Train', 'Validate'], loc='upper left')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:53:19.406944Z","iopub.execute_input":"2023-12-24T22:53:19.407338Z","iopub.status.idle":"2023-12-24T22:53:19.415439Z","shell.execute_reply.started":"2023-12-24T22:53:19.407302Z","shell.execute_reply":"2023-12-24T22:53:19.414438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_learning_curves(res_net_history)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:53:19.416523Z","iopub.execute_input":"2023-12-24T22:53:19.416757Z","iopub.status.idle":"2023-12-24T22:53:20.017806Z","shell.execute_reply.started":"2023-12-24T22:53:19.416736Z","shell.execute_reply":"2023-12-24T22:53:20.016926Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 2.1.5.2  Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:53:20.019226Z","iopub.execute_input":"2023-12-24T22:53:20.019512Z","iopub.status.idle":"2023-12-24T22:53:20.023409Z","shell.execute_reply.started":"2023-12-24T22:53:20.019486Z","shell.execute_reply":"2023-12-24T22:53:20.022415Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_pretrained = ResNet50.predict(X_test_shuffled)\ny_pred_classes_pretrained = np.argmax(y_pred_pretrained, axis=1)\ny_test_classes_pretrained = np.argmax(y_test_one_hot, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:53:20.024642Z","iopub.execute_input":"2023-12-24T22:53:20.024931Z","iopub.status.idle":"2023-12-24T22:53:25.255294Z","shell.execute_reply.started":"2023-12-24T22:53:20.024907Z","shell.execute_reply":"2023-12-24T22:53:25.254369Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"confusion_mtx_resnet = confusion_matrix(y_pred_classes_pretrained, y_test_classes_pretrained)\nprint(\"Confusion Matrix:\")\nprint(confusion_mtx_resnet)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:53:25.256457Z","iopub.execute_input":"2023-12-24T22:53:25.256748Z","iopub.status.idle":"2023-12-24T22:53:25.264635Z","shell.execute_reply.started":"2023-12-24T22:53:25.256723Z","shell.execute_reply":"2023-12-24T22:53:25.263707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nplt.imshow(confusion_mtx_resnet, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix Using Pretrained ResNet-50')\nplt.colorbar()\ntick_marks = np.arange(3)\nplt.xticks(tick_marks, [labels_dict[0], labels_dict[1], labels_dict[2]])\nplt.yticks(tick_marks, [labels_dict[0], labels_dict[1], labels_dict[2]])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:53:25.265817Z","iopub.execute_input":"2023-12-24T22:53:25.266407Z","iopub.status.idle":"2023-12-24T22:53:25.544965Z","shell.execute_reply.started":"2023-12-24T22:53:25.266374Z","shell.execute_reply":"2023-12-24T22:53:25.544033Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 2.1.5.3 Classification Report","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:53:25.545944Z","iopub.execute_input":"2023-12-24T22:53:25.54624Z","iopub.status.idle":"2023-12-24T22:53:25.550433Z","shell.execute_reply.started":"2023-12-24T22:53:25.546215Z","shell.execute_reply":"2023-12-24T22:53:25.54949Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_report_resnet = classification_report(y_test_classes_pretrained, y_pred_classes_pretrained)\nprint(\"Classification Report Using Pretrained ResNet-50:\")\nprint(class_report_resnet)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:53:25.551565Z","iopub.execute_input":"2023-12-24T22:53:25.551878Z","iopub.status.idle":"2023-12-24T22:53:25.571629Z","shell.execute_reply.started":"2023-12-24T22:53:25.551853Z","shell.execute_reply":"2023-12-24T22:53:25.570799Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2 Using NAS (Neural Architecture Search) With Convolution Blocks","metadata":{}},{"cell_type":"code","source":"!pip install autokeras","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:54:27.166019Z","iopub.execute_input":"2023-12-24T22:54:27.166461Z","iopub.status.idle":"2023-12-24T22:54:40.923816Z","shell.execute_reply.started":"2023-12-24T22:54:27.166427Z","shell.execute_reply":"2023-12-24T22:54:40.922765Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import autokeras as ak","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:54:47.722105Z","iopub.execute_input":"2023-12-24T22:54:47.722492Z","iopub.status.idle":"2023-12-24T22:54:49.525399Z","shell.execute_reply.started":"2023-12-24T22:54:47.72246Z","shell.execute_reply":"2023-12-24T22:54:49.524248Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2.2.1 NAS Modeling","metadata":{}},{"cell_type":"code","source":"clf = ak.ImageClassifier(overwrite=True, max_trials=3)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:54:49.526895Z","iopub.execute_input":"2023-12-24T22:54:49.527291Z","iopub.status.idle":"2023-12-24T22:54:49.575565Z","shell.execute_reply.started":"2023-12-24T22:54:49.527264Z","shell.execute_reply":"2023-12-24T22:54:49.5747Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2.2.2 Searching","metadata":{}},{"cell_type":"code","source":"nas = clf.fit(X_train_shuffled, y_train_one_hot, batch_size=32, epochs=10, validation_data=(X_val_shuffled, y_val_one_hot))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T22:54:53.852079Z","iopub.execute_input":"2023-12-24T22:54:53.852462Z","iopub.status.idle":"2023-12-25T01:23:49.495467Z","shell.execute_reply.started":"2023-12-24T22:54:53.85243Z","shell.execute_reply":"2023-12-25T01:23:49.494549Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 2.2.3 Evaluation","metadata":{}},{"cell_type":"markdown","source":"##### 2.2.3.1 Learning Curve ","metadata":{}},{"cell_type":"code","source":"plot_learning_curves(nas)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T01:25:03.162484Z","iopub.execute_input":"2023-12-25T01:25:03.163342Z","iopub.status.idle":"2023-12-25T01:25:03.736081Z","shell.execute_reply.started":"2023-12-25T01:25:03.163301Z","shell.execute_reply":"2023-12-25T01:25:03.735179Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 2.2.3.2 Confusion Matrix","metadata":{}},{"cell_type":"code","source":"y_pred_pretrained = clf.predict(X_test_shuffled)\ny_pred_classes_pretrained = np.argmax(y_pred_pretrained, axis=1)\ny_test_classes_pretrained = np.argmax(y_test_one_hot, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T01:26:09.840927Z","iopub.execute_input":"2023-12-25T01:26:09.84136Z","iopub.status.idle":"2023-12-25T01:27:50.678735Z","shell.execute_reply.started":"2023-12-25T01:26:09.841328Z","shell.execute_reply":"2023-12-25T01:27:50.67786Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"confusion_mtx_nas = confusion_matrix(y_pred_classes_pretrained, y_test_classes_pretrained)\nprint(\"Confusion Matrix:\")\nprint(confusion_mtx_nas)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T01:27:53.448775Z","iopub.execute_input":"2023-12-25T01:27:53.449171Z","iopub.status.idle":"2023-12-25T01:27:53.457666Z","shell.execute_reply.started":"2023-12-25T01:27:53.449142Z","shell.execute_reply":"2023-12-25T01:27:53.456649Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nplt.imshow(confusion_mtx_nas, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix Using NAS')\nplt.colorbar()\ntick_marks = np.arange(3)\nplt.xticks(tick_marks, [labels_dict[0], labels_dict[1], labels_dict[2]])\nplt.yticks(tick_marks, [labels_dict[0], labels_dict[1], labels_dict[2]])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-25T01:27:55.145116Z","iopub.execute_input":"2023-12-25T01:27:55.145892Z","iopub.status.idle":"2023-12-25T01:27:55.493601Z","shell.execute_reply.started":"2023-12-25T01:27:55.14586Z","shell.execute_reply":"2023-12-25T01:27:55.492581Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 2.1.5.3 Classification Report","metadata":{}},{"cell_type":"code","source":"class_report_nas = classification_report(y_test_classes_pretrained, y_pred_classes_pretrained)\nprint(\"Classification Report Using Pretrained NAS\")\nprint(class_report_nas)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T01:32:35.90507Z","iopub.execute_input":"2023-12-25T01:32:35.905516Z","iopub.status.idle":"2023-12-25T01:32:35.924199Z","shell.execute_reply.started":"2023-12-25T01:32:35.905482Z","shell.execute_reply":"2023-12-25T01:32:35.923317Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\nThe results of our experiments highlight the remarkable effectiveness of the Neural Architecture Search (NAS) optimization technique in the context of lymphoma diagnosis in histopathology images. While the pre-trained ResNet-50 model struggled with an accuracy of 50% and exhibited limitations in precision, recall, and F1-score, the NAS-optimized model achieved a perfect accuracy of 100%.\n\nThe NAS approach, with its ability to automatically discover optimal neural network architectures for a given dataset, proved to be a powerful tool for enhancing the performance of the model. The perfect precision, recall, and F1-score across all classes demonstrate the robustness and reliability of the NAS-optimized model in accurately identifying different types of lymphomas.\n\nIn conclusion, the NAS optimization technique emerges as a promising avenue for further research in medical image classification tasks. Its ability to adapt and tailor neural network architectures to specific datasets showcases its potential for improving diagnostic accuracy in histopathology images. Future work may involve exploring the application of NAS on larger datasets and investigating its generalizability across different medical imaging domains.","metadata":{}}]}